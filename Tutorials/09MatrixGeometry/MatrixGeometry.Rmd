---
author: "Department of Econometrics and Business Statistics, Monash University"
date: "Tutorial 9"
output: pdf_document
---

```{r, echo = FALSE}
#rmarkdown::render('MatrixGeometry.Rmd',output_file='MatrixGeometry.pdf')
#rmarkdown::render('MatrixGeometry.Rmd',output_file='MatrixGeometrySols.pdf')
sols<-FALSE
title<-ifelse(sols, 'HDDA Tutorial: Matrices and Factor Analysis
: Solutions','HDDA Tutorial: Matrices and Factor Analysis'
)
```

---
title: "`r title`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Consider the factor model

$$
\mathbf{y}=\boldsymbol{\Lambda}\mathbf{f}+\boldsymbol{\xi}
$$

where $\mathbf{y}$ is a $p\times 1$ vector of observed variables, $\mathbf{f}$ is an $r\times 1$ vector of latent factors with $r<p$, $\boldsymbol{\Lambda}$ is a matrix of loadings and $\boldsymbol{\xi}$ is a $p\times 1$ vector of idiosyncratic errors variables.  Also assume that $\mathbf{f}\sim N(\mathbf{0},\mathbf{I})$ and $\boldsymbol{\xi}\sim N(\mathbf{0},\mathbf{\Psi})$.

1. What are the dimensions of $\boldsymbol{\Lambda}$?

`r if(sols) '*The matrix $\\boldsymbol{\\Lambda}$ must be a $p\\times r$ matrix.  It transforms the r-dimensional factors into points in higher $p$-dimensional space.*'`

2. What is the expected value of $\mathbf{y}$?

`r if(sols) '\\begin{align}E\\left[\\mathbf{y}\\right]&=E\\left[\\boldsymbol{\\Lambda}\\mathbf{f}+\\boldsymbol{\\xi}\\right] \\\\ &=E\\left[\\boldsymbol{\\Lambda}\\mathbf{f}\\right]+E\\left[\\boldsymbol{\\xi}\\right] \\\\ &=\\boldsymbol{\\Lambda}E\\left[\\mathbf{f}\\right]+E\\left[\\boldsymbol{\\xi}\\right] \\\\ &=\\boldsymbol{\\Lambda}0+0\\end{align}'`

`r if(sols) '*The key here is to recognise that $\\boldsymbol{\\Lambda}$ is not a random variable so can be taken outside the expectation.  In general for data that is not mean zero, an intercept can be included.*'`

3. Derive the expected variance covariance matrix of $\mathbf{y}$.  Hint, you can use a rule of matrices that $(\mathbf{A}\mathbf{B})'=\mathbf{B}'\mathbf{A}'$

`r if(sols) '\\begin{align}E\\left[\\mathbf{y}\\mathbf{y}\' \\right]&=E\\left[(\\boldsymbol{\\Lambda}\\mathbf{f}+\\boldsymbol{\\xi})(\\boldsymbol{\\Lambda}\\mathbf{f}+\\boldsymbol{\\xi})\' \\right] \\\\ &=E\\left[(\\boldsymbol{\\Lambda}\\mathbf{f}+\\boldsymbol{\\xi})(\\boldsymbol{(\\Lambda}\\mathbf{f})\'+\\boldsymbol{\\xi}\') \\right] \\\\ &=E\\left[(\\boldsymbol{\\Lambda}\\mathbf{f}+\\boldsymbol{\\xi})(\\boldsymbol{\\mathbf{f}\'\\Lambda}\'+\\boldsymbol{\\xi}\') \\right] \\\\&=E\\left[\\boldsymbol{\\Lambda}\\mathbf{f}\\boldsymbol{\\mathbf{f}\'\\Lambda}\'+\\boldsymbol{\\Lambda}\\mathbf{f}\\boldsymbol{\\xi}\'+\\boldsymbol{\\xi}\\boldsymbol{\\mathbf{f}\'\\Lambda}\'+\\boldsymbol{\\xi}\\boldsymbol{\\xi}\' \\right] \\\\ &=E\\left[\\boldsymbol{\\Lambda}\\mathbf{f}\\boldsymbol{\\mathbf{f}\'\\Lambda}\'\\right]+E\\left[\\boldsymbol{\\Lambda}\\mathbf{f}\\boldsymbol{\\xi}\'\\right]+E\\left[\\boldsymbol{\\xi}\\boldsymbol{\\mathbf{f}\'\\Lambda}\'\\right]+E\\left[\\boldsymbol{\\xi}\\boldsymbol{\\xi}\' \\right]  \\\\ &=\\boldsymbol{\\Lambda}E\\left[\\mathbf{f}\\mathbf{f}\'\\right]\\boldsymbol{\\Lambda}\'+\\boldsymbol{\\Lambda}E\\left[\\mathbf{f}\\boldsymbol{\\xi}\'\\right]+E\\left[\\boldsymbol{\\xi}\\mathbf{f}\'\\right]\\boldsymbol{\\Lambda}\'+E\\left[\\boldsymbol{\\xi}\\boldsymbol{\\xi}\' \\right] \\end{align}'`

`r if(sols) '*There are four expectations. First, $E\\left[\\mathbf{f}\\mathbf{f}\'\\right]$ is equal to $\\mathbf{I}$. The matrices $E\\left[\\mathbf{f}\\boldsymbol{\\xi}\'\\right]$ and $E\\left[\\mathbf{f}\\boldsymbol{\\xi}\'\\right]$ are made up of covariances between factors and idiosyncratic errors which are assumed to be 0.  Finally $E\\left[\\boldsymbol{\\xi}\\boldsymbol{\\xi}\' \\right]$ is assumed to be a diagonal matrix $\\boldsymbol{\\Psi}$.  Putting all this together yields  $E\\left[\\mathbf{y}\\mathbf{y}\' \\right]=\\boldsymbol{\\Lambda}\\boldsymbol{\\Lambda}\'+\\boldsymbol{\\Psi}$*'`